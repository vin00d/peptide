{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.pretrained.lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_func\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fasta + BioPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from peptide.basics import *\n",
    "from peptide.preprocessing.data import (\n",
    "    ProteinDataset,\n",
    "    ACPDataset,\n",
    "    AMPDataset,\n",
    "    DNABindDataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">YP_025292.1 toxic membrane protein, small\n",
      "MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "record = SeqRecord(\n",
    "    Seq(\"MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\"),\n",
    "    id=\"YP_025292.1\",\n",
    "    name=\"HokC\",\n",
    "    description=\"toxic membrane protein, small\",\n",
    ")\n",
    "print(record.format('fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqRecord(seq=Seq('MKQHK'), id='YP_025292.1', name='HokC', description='toxic membrane protein, small', dbxrefs=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acp_data = ACPDataset(DATA_STORE)\n",
    "amp_data = AMPDataset(DATA_STORE)\n",
    "dnabind_data = DNABindDataset(DATA_STORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fasta_files(ds: ProteinDataset, out_dir: str = None, use_seq_max_len: bool = False):\n",
    "    \"\"\"Generate a fasta files for the given protein dataset.\"\"\"\n",
    "\n",
    "    ds_name = type(ds).__name__\n",
    "    location = out_dir if out_dir else ds.location\n",
    "\n",
    "    for df, split in zip([ds.train, ds.test], ['train', 'test']):\n",
    "        if use_seq_max_len:\n",
    "            file_name = f\"{location}/{ds_name}_{split}_seqlen_{ds.max_seq_len}.fasta\"\n",
    "            # create list of seq records, with truncated sequences\n",
    "            seq_recs = [\n",
    "                SeqRecord(\n",
    "                    Seq(\"\".join(df.loc[i, \"sequence\"])), id=str(i))\n",
    "                    [:ds.max_seq_len] \n",
    "                    for i in range(len(df))\n",
    "            ]\n",
    "        else:\n",
    "            file_name = f\"{location}/{ds_name}_{split}.fasta\"\n",
    "            # create list of seq records, with full sequences\n",
    "            seq_recs = [\n",
    "                SeqRecord(Seq(\"\".join(df.loc[i, \"sequence\"])), id=str(i))\n",
    "                for i in range(len(df))\n",
    "            ]\n",
    "\n",
    "        # write fasta file\n",
    "        with open(file_name, \"w\") as output_handle:\n",
    "            SeqIO.write(seq_recs, output_handle, \"fasta\")\n",
    "\n",
    "        print(\n",
    "            f\"Created {file_name} with {len(seq_recs)} sequence records\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /home/vinod/.peptide/datasets/ACPDataset_train.fasta with 1378 sequence records\n",
      "Created /home/vinod/.peptide/datasets/ACPDataset_test.fasta with 344 sequence records\n"
     ]
    }
   ],
   "source": [
    "generate_fasta_files(acp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /home/vinod/.peptide/datasets/AMPDataset_train.fasta with 3234 sequence records\n",
      "Created /home/vinod/.peptide/datasets/AMPDataset_test.fasta with 808 sequence records\n"
     ]
    }
   ],
   "source": [
    "generate_fasta_files(amp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /home/vinod/.peptide/datasets/AMPDataset_train_seqlen_150.fasta with 3234 sequence records\n",
      "Created /home/vinod/.peptide/datasets/AMPDataset_test_seqlen_150.fasta with 808 sequence records\n"
     ]
    }
   ],
   "source": [
    "generate_fasta_files(amp_data, use_seq_max_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /home/vinod/.peptide/datasets/DNABindDataset_train.fasta with 14189 sequence records\n",
      "Created /home/vinod/.peptide/datasets/DNABindDataset_test.fasta with 2272 sequence records\n"
     ]
    }
   ],
   "source": [
    "generate_fasta_files(dnabind_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /home/vinod/.peptide/datasets/DNABindDataset_train_seqlen_300.fasta with 14189 sequence records\n",
      "Created /home/vinod/.peptide/datasets/DNABindDataset_test_seqlen_300.fasta with 2272 sequence records\n"
     ]
    }
   ],
   "source": [
    "generate_fasta_files(dnabind_data, use_seq_max_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample python commands to generate embeddings from pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACP**\n",
    "```\n",
    "python embed_sequences.py -o ~/.peptide/datasets/lstm/acp_nopool_train.h5 ~/.peptide/datasets/fasta/ACPDataset_train.fasta\n",
    "# loading the pre-trained ProSE MT model\n",
    "# writing: /home/vinod/.peptide/datasets/lstm/acp_nopool_train.h5\n",
    "# embedding with pool=none\n",
    "\n",
    "python embed_sequences.py --pool avg -o ~/.peptide/datasets/lstm/acp_avgpool_test.h5 ~/.peptide/datasets/fasta/ACPDataset_test.fasta\n",
    "# loading the pre-trained ProSE MT model\n",
    "# writing: /home/vinod/.peptide/datasets/lstm/acp_avgpool_test.h5\n",
    "# embedding with pool=avg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AMP**\n",
    "- For AMP - some type of pooling needs to be done on the non-truncated sequences as `train` and `test` have different max seq lengths\n",
    "```\n",
    "python embed_sequences.py --pool avg -o ~/.peptide/datasets/lstm/amp_avgpool_train.h5 ~/.peptide/datasets/fasta/AMPDataset_train.fasta\n",
    "# loading the pre-trained ProSE MT model\n",
    "# writing: /home/vinod/.peptide/datasets/lstm/amp_avgpool_train.h5\n",
    "# embedding with pool=avg\n",
    "```\n",
    "- And no pooling can only be done on truncated sequences since the lengths match\n",
    "```\n",
    "python embed_sequences.py -o ~/.peptide/datasets/lstm/amp_nopool_test_seqlen_150.h5 ~/.peptide/datasets/fasta/AMPDataset_test_seqlen_150.fasta\n",
    "# loading the pre-trained ProSE MT model\n",
    "# writing: /home/vinod/.peptide/datasets/lstm/amp_nopool_test_seqlen_150.h5\n",
    "# embedding with pool=none\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DNA Binding**\n",
    "- Same as AMP - some pooling needed for the full non-truncated sequences\n",
    "```\n",
    "python embed_sequences.py -o ~/.peptide/datasets/lstm/dnabind_nopool_train_seqlen_300.h5 ~/.peptide/datasets/fasta/DNABindDataset_train_seqlen_300.fasta\n",
    "# loading the pre-trained ProSE MT model\n",
    "# writing: /home/vinod/.peptide/datasets/lstm/dnabind_nopool_train_seqlen_300.h5\n",
    "# embedding with pool=none\n",
    "```\n",
    "- And pooling can be done on the truncated sequences\n",
    "```\n",
    "python embed_sequences.py --pool avg -o ~/.peptide/datasets/lstm/dnabind_avgpool_test.h5 ~/.peptide/datasets/fasta/DNABindDataset_test.fasta\n",
    "# loading the pre-trained ProSE MT model\n",
    "# writing: /home/vinod/.peptide/datasets/lstm/dnabind_avgpool_test.h5\n",
    "# embedding with pool=avg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/acp_test_avgpool.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['1', '2', '3', '4']>\n",
      "--\n",
      "<class 'h5py._hl.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    print(\"--\")\n",
    "    # get first object name/key; may or may NOT be a group\n",
    "    a_group_key = list(f.keys())[1]\n",
    "\n",
    "    # get the object type for a_group_key: usually group or dataset\n",
    "    print(type(f[a_group_key])) \n",
    "\n",
    "    # If a_group_key is a group name, \n",
    "    # this gets the object names in the group and returns as a list\n",
    "    data = list(f[a_group_key])\n",
    "\n",
    "    # If a_group_key is a dataset name, \n",
    "    # this gets the dataset values and returns as a list\n",
    "    data = list(f[a_group_key])\n",
    "    # preferred methods to get dataset values:\n",
    "    ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "    ds_arr = f[a_group_key][()]  # returns as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6165,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04545455,  0.04545455,  0.11363637, ...,  0.09409127,\n",
       "       -0.05029093,  0.62466204], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(filename, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indx: 1\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "(6165,)\n",
      "indx: 2\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "(6165,)\n",
      "indx: 3\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "(6165,)\n",
      "indx: 4\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "(6165,)\n"
     ]
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(f'indx: {key}') #Names of the root level object names in HDF5 file - can be groups or datasets.\n",
    "    print(type(f[key])) # get the object type: usually group or dataset\n",
    "    data = f[key][()]\n",
    "    print(data.shape)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'H'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/vinod/code/myrepos/peptide/05_pretrained_lstm.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vinod/code/myrepos/peptide/05_pretrained_lstm.ipynb#ch0000028?line=0'>1</a>\u001b[0m acp_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m/home/vinod/.peptide/datasets/lstm/acp_nopool_train.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/peptide/lib/python3.9/site-packages/torch/serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[1;32m    712\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 713\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/peptide/lib/python3.9/site-packages/torch/serialization.py:920\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(f, \u001b[39m'\u001b[39m\u001b[39mreadinto\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m (\u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m2\u001b[39m):\n\u001b[1;32m    915\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived object of type \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(f)\u001b[39m}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    918\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfunctionality.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 920\u001b[0m magic_number \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39;49mload(f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m magic_number \u001b[39m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m    922\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid magic number; corrupt file?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'H'."
     ]
    }
   ],
   "source": [
    "acp_train = torch.load('/home/vinod/.peptide/datasets/lstm/acp_nopool_train.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('peptide')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed1fe5d2b8444463e19b00657a175b9cae3e282d841010e10efaed3bb2bffc1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
