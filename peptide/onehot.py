# AUTOGENERATED! DO NOT EDIT! File to edit: 03_onehot.ipynb (unless otherwise specified).

__all__ = ['create_param_grid', 'run_gridsearch']

# Cell

from .imports import *
from .basics import *
from .core import *
from .data import (
    ProteinDataset,
    ACPDataset,
    AMPDataset,
    DNABindDataset,
)

# Cell
def create_param_grid(model: str) -> dict:
    """Create and return a gird search param grid"""
    param_grid = {}

    if model == "lr":
        param_grid = [
            {
                "classifier__solver": ["lbfgs"],
                "classifier__penalty": ["l2"],
                "classifier__C": np.logspace(-2, 2, 5),  # default=1.0
                "classifier__max_iter": [1000, 5000, 10000],  # default=100
            },
            {
                "classifier__solver": ["liblinear"],
                "classifier__penalty": ["l1", "l2"],
                "classifier__C": np.logspace(-2, 2, 5),
                "classifier__max_iter": [1000, 5000, 10000],
            },
        ]
    elif model == "svm":
        param_grid = [
            {
                "classifier__loss": ["hinge"],  # default=’squared_hinge’
                "classifier__penalty": ["l2"],  # default=’l2’
                "classifier__C": np.logspace(-2, 2, 5),  # default=1.0
                "classifier__max_iter": [5000, 10000],  # default=1000
            },
            {
                "classifier__loss": ["squared_hinge"],
                "classifier__penalty": ["l1", "l2"],
                "classifier__C": np.logspace(-2, 2, 5),
                "classifier__max_iter": [5000, 10000],
            },
        ]
    elif model == "xgb":
        param_grid = {
            # "colsample_bytree": uniform(0.7, 0.3),
            # "classifier__gamma": uniform(0, 0.5),
            "classifier__learning_rate": np.linspace(0.03, 0.3, 4),  # default 0.1
            "classifier__max_depth": [3, 4, 5, 6],  # default 3
            "classifier__n_estimators": [100, 150],  # default 100
            # "subsample": uniform(0.6, 0.4),
        }
    else:
        raise Exception("model needs to be one of 'lr', 'svm' or 'xgb'")

    return param_grid


# Cell
def run_gridsearch(X_train: pd.DataFrame, y_train: np.ndarray, models: list) -> None:
    """Run grid search for all models given X_train and y_train and print best best score and results."""

    def _gridsearch(
        model: str, X_train: pd.DataFrame, y_train: np.array
    ) -> GridSearchCV:

        model_pipeline = create_pipeline(model, len(X_train.columns))
        param_grid = create_param_grid(model)

        grid_search = GridSearchCV(
            estimator=model_pipeline,
            param_grid=param_grid,
            n_jobs=-1,
            cv=3,
            scoring="accuracy",
            error_score=0,
        )
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore")
            grid_result = grid_search.fit(X_train, y_train)
        return grid_result

    # call helper for each model
    grid_results = {}
    for model in models:
        print(f"Starting grid search for {model}")
        grid_results[model] = _gridsearch(model, X_train, y_train)
        print(f"Completed grid search for {model}")

    for model in models:
        print(
            f"{model}:: Best score: {grid_results[model].best_score_:.3f} using {grid_results[model].best_params_}"
        )
